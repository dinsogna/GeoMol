Arguments are...
log_dir: dom_log
data_dir: data/QM9/qm9/
split_path: data/QM9/splits/split0.npy
trained_local_model: None
restart_dir: hnin_best
dataset: qm9
seed: 0
n_epochs: 50
warmup_epochs: 2
batch_size: 1
lr: 0.001
num_workers: 0
optimizer: adam
scheduler: plateau
verbose: False
model_dim: 25
random_vec_dim: 10
random_vec_std: 1
random_alpha: False
n_true_confs: 1
n_model_confs: 1
gnn1_depth: 3
gnn1_n_layers: 2
gnn2_depth: 3
gnn2_n_layers: 2
encoder_n_head: 2
coord_pred_n_layers: 2
d_mlp_n_layers: 1
h_mol_mlp_n_layers: 1
alpha_mlp_n_layers: 2
c_mlp_n_layers: 1
global_transformer: False
loss_type: ot_emd
teacher_force: False
separate_opts: False
Arguments are...
log_dir: dom_log
data_dir: data/QM9/qm9/
split_path: data/QM9/splits/split0.npy
trained_local_model: None
restart_dir: hnin_best
dataset: qm9
seed: 0
n_epochs: 50
warmup_epochs: 2
batch_size: 1
lr: 0.001
num_workers: 0
optimizer: adam
scheduler: plateau
verbose: False
model_dim: 25
random_vec_dim: 10
random_vec_std: 1
random_alpha: False
n_true_confs: 1
n_model_confs: 1
gnn1_depth: 3
gnn1_n_layers: 2
gnn2_depth: 3
gnn2_n_layers: 2
encoder_n_head: 2
coord_pred_n_layers: 2
d_mlp_n_layers: 1
h_mol_mlp_n_layers: 1
alpha_mlp_n_layers: 2
c_mlp_n_layers: 1
global_transformer: False
loss_type: ot_emd
teacher_force: False
separate_opts: False

Model parameters are:
hyperparams:
  alpha_mlp:
    n_layers: 2
  c_mlp:
    n_layers: 1
  coord_pred:
    n_layers: 2
  d_mlp:
    n_layers: 1
  encoder:
    n_head: 2
  global_transformer: False
  gnn1:
    depth: 3
    n_layers: 2
  gnn2:
    depth: 3
    n_layers: 2
  h_mol_mlp:
    n_layers: 1
  loss_type: ot_emd
  model_dim: 25
  n_model_confs: 1
  n_true_confs: 1
  random_alpha: False
  random_vec_dim: 10
  random_vec_std: 1
  teacher_force: False
num_edge_features: 4
num_node_features: 44


Starting training...
Epoch 1: Training Loss 2.312744493752718
Epoch 1: Validation Loss 1.5218899057805537
Epoch 2: Training Loss 2.61943643502295
Epoch 2: Validation Loss -0.6067471731230617
Epoch 3: Training Loss 2.4823824660241605
Epoch 3: Validation Loss -0.7388821893017739
Epoch 4: Training Loss 2.4393483078092335
Epoch 4: Validation Loss -0.8087024643421173
Epoch 5: Training Loss 2.4025214549899103
Epoch 5: Validation Loss -0.5125490087606013
Epoch 6: Training Loss 2.927217576485872
Epoch 6: Validation Loss -0.1288693726673955
Epoch 7: Training Loss 3.8237943828999996
Epoch 7: Validation Loss 1.0354280501417816
Epoch 8: Training Loss 4.162853623750806
Epoch 8: Validation Loss 1.0732091936580836
Epoch 9: Training Loss 4.0295313556313515
Epoch 9: Validation Loss 0.7166571796946227
Epoch 10: Training Loss 4.061764306101203
Epoch 10: Validation Loss 0.7109616796821355
Epoch 11: Training Loss 4.0338582351148125
Epoch 11: Validation Loss 0.9831301882974803
Epoch 12: Training Loss 4.100163275688887
Epoch 12: Validation Loss 0.8699013203456998
Epoch 13: Training Loss 3.906414776235819
Epoch 13: Validation Loss 1.185114072188735
Epoch 14: Training Loss 4.098682557070255
Epoch 14: Validation Loss 1.0097873868755995
Epoch 15: Training Loss 4.091265632611513
Epoch 15: Validation Loss 1.2858368465341627
Epoch 16: Training Loss 4.407831973040104
Epoch 16: Validation Loss 1.1370428779497743
Epoch 17: Training Loss 4.059742901390791
Epoch 17: Validation Loss 0.7159271098338068
Epoch 18: Training Loss 4.0088227626264095
Epoch 18: Validation Loss 1.335229029715061
Epoch 19: Training Loss 4.037361884212494
Epoch 19: Validation Loss 0.7132938955286517
Epoch 20: Training Loss 3.809063574400544
Epoch 20: Validation Loss 0.6238193599972874
Epoch 21: Training Loss 3.9389495209664105
Epoch 21: Validation Loss 0.5843714907448739
Epoch 22: Training Loss 3.7410238445818425
Epoch 22: Validation Loss 0.48237369241565464
Epoch 23: Training Loss 3.6434227863103152
Epoch 23: Validation Loss 0.4567591731948778
Epoch 24: Training Loss 3.6098946496263147
Epoch 24: Validation Loss 0.4062061698436737
Epoch 25: Training Loss 3.645917839485407
Epoch 25: Validation Loss 0.45001582630723713
Epoch 26: Training Loss 3.667137626987696
Epoch 26: Validation Loss 0.43023708852380516
Epoch 27: Training Loss 3.5537282665610315
Epoch 27: Validation Loss 0.44946157653443514
Epoch 28: Training Loss 3.54284542991519
Epoch 28: Validation Loss 0.5641290571913123
Epoch 29: Training Loss 3.460203595820069
Epoch 29: Validation Loss 0.29740921695530415
Epoch 30: Training Loss 3.5139818013101816
Epoch 30: Validation Loss 0.25445419156365096
Epoch 31: Training Loss 3.4485839796572924
Epoch 31: Validation Loss 0.2909913850994781
Epoch 32: Training Loss 3.4473507020354273
Epoch 32: Validation Loss 0.22282284048758447
Epoch 33: Training Loss 3.4946352032124994
Epoch 33: Validation Loss 0.17980578345619141
Epoch 34: Training Loss 3.3946783190578222
Epoch 34: Validation Loss 0.06148555830353871
Epoch 35: Training Loss 3.3586800679415463
Epoch 35: Validation Loss 0.3089774460582994
Epoch 36: Training Loss 3.3864957374572753
Epoch 36: Validation Loss 0.19241307839751243
Epoch 37: Training Loss 3.355344893601537
Epoch 37: Validation Loss 0.18528157250210642
Epoch 38: Training Loss 3.2811647337257863
Epoch 38: Validation Loss 0.06060451248334721
Epoch 39: Training Loss 3.2887543985366823
Epoch 39: Validation Loss 0.06261157535016537
Epoch 40: Training Loss 3.2576747807472946
Epoch 40: Validation Loss 0.14025417119450867
Epoch 41: Training Loss 3.249855190470815
Epoch 41: Validation Loss 0.04479181266855448
Epoch 42: Training Loss 3.235460533887148
Epoch 42: Validation Loss 0.03273390160873532
Epoch 43: Training Loss 3.2400344835460184
Epoch 43: Validation Loss 0.08215266789868474
Epoch 44: Training Loss 3.2322189607828857
Epoch 44: Validation Loss -0.006853172876988538
Epoch 45: Training Loss 3.2191748853474857
Epoch 45: Validation Loss 0.08257020542677491
Epoch 46: Training Loss 3.2822540207087996
Epoch 46: Validation Loss 0.009466320478823035
Epoch 47: Training Loss 3.198136628726125
Epoch 47: Validation Loss 0.032335409849882125
Epoch 48: Training Loss 3.1907093117028476
Epoch 48: Validation Loss -0.06343878898117691
Epoch 49: Training Loss 3.2027489300847054
Epoch 49: Validation Loss 0.03997782984189689
Best Validation Loss -0.8087024643421173 on Epoch 4
